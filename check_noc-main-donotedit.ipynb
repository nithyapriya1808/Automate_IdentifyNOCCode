{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VEERANI2\\.conda\\envs\\ana_envi\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdfplumber\n",
    "from pdf2docx import Converter\n",
    "from pdfminer3.layout import LAParams, LTTextBox\n",
    "from pdfminer3.pdfpage import PDFPage\n",
    "from pdfminer3.pdfinterp import PDFResourceManager\n",
    "from pdfminer3.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer3.converter import PDFPageAggregator\n",
    "from pdfminer3.converter import TextConverter\n",
    "import io\n",
    "import docx2txt\n",
    "from docx import Document\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import win32com.client\n",
    "import PyPDF2\n",
    "#import camelot\n",
    "import fitz\n",
    "import sys\n",
    "from pdfrw import PdfReader\n",
    "import operator\n",
    "import wx\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> using pdfplumber </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pdfplumber.open(r'noccodes.pdf') as pdf:\n",
    "#     first_page = pdf.pages[487]\n",
    "#     print(first_page.extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> using pdfminer </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = open('resume_text.txt', 'a')\n",
    "resource_manager = PDFResourceManager()\n",
    "fake_file_handle = io.StringIO()\n",
    "converter = TextConverter(resource_manager, fake_file_handle, laparams=LAParams())\n",
    "page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "\n",
    "with open('resume.pdf', 'rb') as fh:\n",
    "\n",
    "    for page in PDFPage.get_pages(fh,\n",
    "                                  caching=True,\n",
    "                                  check_extractable=True):\n",
    "        page_interpreter.process_page(page)\n",
    "#         print()\n",
    "        file_object.write(fake_file_handle.getvalue())\n",
    "#     text = fake_file_handle.getvalue()\n",
    "#         print(text)\n",
    "\n",
    "# close open handles\n",
    "converter.close()\n",
    "fake_file_handle.close()\n",
    "file_object.close()\n",
    "print(\"Done...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> using pdf to word </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = win32com.client.Dispatch(\"Word.Application\")\n",
    "word.visible = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Converter_pdf2docx(source,destination):\n",
    "    pdf_file  = source\n",
    "    docx_file = destination\n",
    "    cv = Converter(pdf_file)\n",
    "    cv.convert(docx_file, start=0, end=None)\n",
    "    cv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Converter_pdf2docx('resume.pdf','text.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "noc_codes=pd.read_csv(\"noc_names.csv\", encoding= 'unicode_escape',dtype = {'NOC Code': str,'Code Division': str,\n",
    "                                                      'Code Name': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOC Code</th>\n",
       "      <th>Code Division</th>\n",
       "      <th>Code Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>9616</td>\n",
       "      <td>D</td>\n",
       "      <td>Labourers in textile processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>9617</td>\n",
       "      <td>D</td>\n",
       "      <td>Labourers in food and beverage processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>9618</td>\n",
       "      <td>D</td>\n",
       "      <td>Labourers in fish and seafood processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>9619</td>\n",
       "      <td>D</td>\n",
       "      <td>Other labourers in processing, manufacturing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NOC Code Code Division                                          Code Name\n",
       "496     9616             D                    Labourers in textile processing\n",
       "497     9617             D          Labourers in food and beverage processing\n",
       "498     9618             D           Labourers in fish and seafood processing\n",
       "499     9619             D  Other labourers in processing, manufacturing a...\n",
       "500      NaN           NaN                                                NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noc_codes.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = '9616'\n",
    "string2 = '9617'\n",
    "  \n",
    "# opening a text file\n",
    "file1 = open(\"nocedited_text.txt\", \"r\")\n",
    "\n",
    "def findword(string1,file1):\n",
    "    # setting flag and index to 0\n",
    "    flag = 0\n",
    "    index = 0\n",
    "    # Loop through the file line by line\n",
    "    for line in file1:  \n",
    "        index+=1 \n",
    "\n",
    "        # checking string is present in line or not\n",
    "        if string1 in line:\n",
    "            flag = 1\n",
    "            break \n",
    "\n",
    "    # checking condition for string found or not\n",
    "    if flag == 0:\n",
    "        print('String', string1 , 'Not Found') \n",
    "    else:\n",
    "        print('String', string1, 'Found In Line', index)\n",
    "\n",
    "    # closing text file    \n",
    "     \n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index1=findword(string1,file1)\n",
    "index2=findword(string2,file1)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_contents = file1.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_TEXT = docx2txt.process(\"resume.docx\")\n",
    "with open(\"resume_text.txt\", \"w\") as text_file:\n",
    "    print(MY_TEXT, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('noc_text.txt') as f:\n",
    "    contents = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document()\n",
    " \n",
    "files = glob.glob(\"*.txt\")\n",
    "print(files)\n",
    "file = input(\"Scrivi il nome del file senza .txt: \") + \".txt\"\n",
    "\n",
    "\n",
    "with open(file, 'rb', encoding= 'unicode_escape') as openfile:\n",
    "#     openfile.encode('utf-8').strip()\n",
    "    line = openfile.read()\n",
    "    doc.add_paragraph(line)\n",
    "    doc.save(file + \".docx\")\n",
    "\n",
    "os.system(file + \".docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_header(filename):\n",
    "    with open(filename) as f:\n",
    "        first = f.read(1)\n",
    "    return first not in '.-0123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_header(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting headings and paragraphs\n",
    "def headers_para(doc, size_tag):\n",
    "    \"\"\"Scrapes headers & paragraphs from PDF and return texts with element tags.\n",
    "    :param doc: PDF document to iterate through\n",
    "    :type doc: <class 'fitz.fitz.Document'>\n",
    "    :param size_tag: textual element tags for each size\n",
    "    :type size_tag: dict\n",
    "    :rtype: list\n",
    "    :return: texts with pre-prended element tags\n",
    "    \"\"\"\n",
    "    header_para = []  # list with headers and paragraphs\n",
    "    first = True  # boolean operator for first header\n",
    "    previous_s = {}  # previous span\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.getText(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # this block contains text\n",
    "\n",
    "                # REMEMBER: multiple fonts and sizes are possible IN one block\n",
    "\n",
    "                block_string = \"\"  # text found in block\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        if s['text'].strip():  # removing whitespaces:\n",
    "                            if first:\n",
    "                                previous_s = s\n",
    "                                first = False\n",
    "                                block_string = size_tag[s['size']] + s['text']\n",
    "                            else:\n",
    "                                if s['size'] == previous_s['size']:\n",
    "\n",
    "                                    if block_string and all((c == \"|\") for c in block_string):\n",
    "                                        # block_string only contains pipes\n",
    "                                        block_string = size_tag[s['size']] + s['text']\n",
    "                                    if block_string == \"\":\n",
    "                                        # new block has started, so append size tag\n",
    "                                        block_string = size_tag[s['size']] + s['text']\n",
    "                                    else:  # in the same block, so concatenate strings\n",
    "                                        block_string += \" \" + s['text']\n",
    "\n",
    "                                else:\n",
    "                                    header_para.append(block_string)\n",
    "                                    block_string = size_tag[s['size']] + s['text']\n",
    "\n",
    "                                previous_s = s\n",
    "\n",
    "                    # new block started, indicating with a pipe\n",
    "                    block_string += \"|\"\n",
    "\n",
    "                header_para.append(block_string)\n",
    "\n",
    "    return header_para\n",
    "\n",
    "def font_tags(font_counts, styles):\n",
    "    \"\"\"Returns dictionary with font sizes as keys and tags as value.\n",
    "    :param font_counts: (font_size, count) for all fonts occuring in document\n",
    "    :type font_counts: list\n",
    "    :param styles: all styles found in the document\n",
    "    :type styles: dict\n",
    "    :rtype: dict\n",
    "    :return: all element tags based on font-sizes\n",
    "    \"\"\"\n",
    "    p_style = styles[font_counts[0][0]]  # get style for most used font by count (paragraph)\n",
    "    p_size = p_style['size']  # get the paragraph's size\n",
    "\n",
    "    # sorting the font sizes high to low, so that we can append the right integer to each tag \n",
    "    font_sizes = []\n",
    "    for (font_size, count) in font_counts:\n",
    "        font_sizes.append(float(font_size))\n",
    "    font_sizes.sort(reverse=True)\n",
    "\n",
    "    # aggregating the tags for each font size\n",
    "    idx = 0\n",
    "    size_tag = {}\n",
    "    for size in font_sizes:\n",
    "        idx += 1\n",
    "        if size == p_size:\n",
    "            idx = 0\n",
    "            size_tag[size] = '<p>'\n",
    "        if size > p_size:\n",
    "            size_tag[size] = '<h{0}>'.format(idx)\n",
    "        elif size < p_size:\n",
    "            size_tag[size] = '<s{0}>'.format(idx)\n",
    "\n",
    "    return size_tag\n",
    "\n",
    "def fonts(doc, granularity=False):\n",
    "    \"\"\"Extracts fonts and their usage in PDF documents.\n",
    "    :param doc: PDF document to iterate through\n",
    "    :type doc: <class 'fitz.fitz.Document'>\n",
    "    :param granularity: also use 'font', 'flags' and 'color' to discriminate text\n",
    "    :type granularity: bool\n",
    "    :rtype: [(font_size, count), (font_size, count}], dict\n",
    "    :return: most used fonts sorted by count, font style information\n",
    "    \"\"\"\n",
    "    styles = {}\n",
    "    font_counts = {}\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.getText(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # block contains text\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        if granularity:\n",
    "                            identifier = \"{0}_{1}_{2}_{3}\".format(s['size'], s['flags'], s['font'], s['color'])\n",
    "                            styles[identifier] = {'size': s['size'], 'flags': s['flags'], 'font': s['font'],\n",
    "                                                  'color': s['color']}\n",
    "                        else:\n",
    "                            identifier = \"{0}\".format(s['size'])\n",
    "                            styles[identifier] = {'size': s['size'], 'font': s['font']}\n",
    "\n",
    "                        font_counts[identifier] = font_counts.get(identifier, 0) + 1  # count the fonts usage\n",
    "\n",
    "    font_counts = sorted(font_counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    if len(font_counts) < 1:\n",
    "        raise ValueError(\"Zero discriminating fonts found!\")\n",
    "\n",
    "    return font_counts, styles\n",
    "\n",
    "def headings(doc):\n",
    "    font_counts_, styles_=fonts(doc)\n",
    "    size_tag_=font_tags(font_counts_, styles_)\n",
    "    header_para_=headers_para(doc,size_tag_)\n",
    "    headings=list()\n",
    "    for val in header_para_:\n",
    "        if \"<h\" in val:\n",
    "            headings.append(val)\n",
    "    val1=[sub.split(\"|\") for sub in headings]\n",
    "    flat_list = [item for sublist in val1 for item in sublist]\n",
    "    df = pd.DataFrame(flat_list)\n",
    "    return df\n",
    "\n",
    "def sent_tags(doc):\n",
    "    header_para = []  # list with headers and paragraphs\n",
    "    first = True  # boolean operator for first header\n",
    "    previous_s = {}  # previous span\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.getText(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # this block contains text\n",
    "\n",
    "                # REMEMBER: multiple fonts and sizes are possible IN one block\n",
    "\n",
    "                block_string = \"\"  # text found in block\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        if s['text'].strip():  # removing whitespaces:\n",
    "                            if first:\n",
    "                                previous_s = s\n",
    "                                first = False\n",
    "                                block_string = s['text']\n",
    "                            else:\n",
    "                                if s['size'] == previous_s['size']:\n",
    "\n",
    "                                    if block_string and all((c == \"|\") for c in block_string):\n",
    "                                        # block_string only contains pipes\n",
    "                                        block_string = s['text']\n",
    "                                    if block_string == \"\":\n",
    "                                        # new block has started, so append size tag\n",
    "                                        block_string = s['text']\n",
    "                                    else:  # in the same block, so concatenate strings\n",
    "                                        block_string += s['text']\n",
    "\n",
    "                                else:\n",
    "                                    header_para.append(block_string)\n",
    "                                    block_string = s['text']\n",
    "\n",
    "                                previous_s = s\n",
    "\n",
    "                    # new block started, indicating with a pipe\n",
    "    #                 block_string = list(map(lambda st: str.replace(st, \",\", \" and \"), block_string)) \n",
    "                    block_string += \"|\"\n",
    "\n",
    "                header_para.append(block_string)\n",
    "\n",
    "    return header_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open('noccodes_edited.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_string = doc.name\n",
    "\n",
    "split_string = a_string.split(\".\", 1)\n",
    "\n",
    "substring = split_string[0]\n",
    "# substring=substring.replace(\"\\\\\",\"\").replace(\" \",\"\")\n",
    "\n",
    "header_para = []  # list with headers and paragraphs\n",
    "first = True  # boolean operator for first header\n",
    "previous_s = {}  # previous span\n",
    "header_para=sent_tags(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings(doc).to_csv(\"headings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_counts_, styles_=fonts(doc)\n",
    "size_tag_=font_tags(font_counts_, styles_)\n",
    "header_para_=headers_para(doc,size_tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_para_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(header_para_)):\n",
    "    print (header_para_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list[5 : 8] = [''.join(test_list[5 : 8])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(header_para_)):\n",
    "    if (header_para_[i].tolower().contains('<h3>')):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = [idx for idx, s in enumerate(header_para_) if \"<h3>\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_para_[md[0]]\n",
    "header_para_[md[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(header_para_) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.append(len(header_para_) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={}\n",
    "for i in range(0,len(md)):\n",
    "#     print(i)\n",
    "    d[\"string{0}\".format(i)] = ''.join(header_para_[md[i-1]:md[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_=d.keys()\n",
    "# keys_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1={}\n",
    "for val in keys_:\n",
    "#     print(val)\n",
    "    d1[d[val].split('|', 1)[0]]=d[val]\n",
    "#     del d[val] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {x.replace('<h3>', ''): v \n",
    "     for x, v in d1.items()}\n",
    "d1 = {x.replace('\\xa0', ''): v \n",
    "     for x, v in d1.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1['9534 Furniture finishers and refinishers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_ratio_and_distance(s, t, ratio_calc = False):\n",
    "    \"\"\" levenshtein_ratio_and_distance:\n",
    "        Calculates levenshtein distance between two strings.\n",
    "        If ratio_calc = True, the function computes the\n",
    "        levenshtein distance ratio of similarity between two strings\n",
    "        For all i and j, distance[i,j] will contain the Levenshtein\n",
    "        distance between the first i characters of s and the\n",
    "        first j characters of t\n",
    "    \"\"\"\n",
    "    # Initialize matrix of zeros\n",
    "    rows = len(s)+1\n",
    "    cols = len(t)+1\n",
    "    distance = np.zeros((rows,cols),dtype = int)\n",
    "\n",
    "    # Populate matrix of zeros with the indeces of each character of both strings\n",
    "    for i in range(1, rows):\n",
    "        for k in range(1,cols):\n",
    "            distance[i][0] = i\n",
    "            distance[0][k] = k\n",
    "\n",
    "    # Iterate over the matrix to compute the cost of deletions,insertions and/or substitutions    \n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            if s[row-1] == t[col-1]:\n",
    "                cost = 0 # If the characters are the same in the two strings in a given position [i,j] then the cost is 0\n",
    "            else:\n",
    "                # In order to align the results with those of the Python Levenshtein package, if we choose to calculate the ratio\n",
    "                # the cost of a substitution is 2. If we calculate just distance, then the cost of a substitution is 1.\n",
    "                if ratio_calc == True:\n",
    "                    cost = 2\n",
    "                else:\n",
    "                    cost = 1\n",
    "            distance[row][col] = min(distance[row-1][col] + 1,      # Cost of deletions\n",
    "                                 distance[row][col-1] + 1,          # Cost of insertions\n",
    "                                 distance[row-1][col-1] + cost)     # Cost of substitutions\n",
    "    if ratio_calc == True:\n",
    "        # Computation of the Levenshtein Distance Ratio\n",
    "        Ratio = ((len(s)+len(t)) - distance[row][col]) / (len(s)+len(t))\n",
    "        return Ratio\n",
    "    else:\n",
    "        # print(distance) # Uncomment if you want to see the matrix showing how the algorithm computes the cost of deletions,\n",
    "        # insertions and/or substitutions\n",
    "        # This is the minimum number of edits needed to convert string a to string b\n",
    "        return \" \"\n",
    "#         return \"The strings are {} edits away\".format(distance[row][col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resume_text.txt') as f:\n",
    "    contents = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in d1.keys():\n",
    "    Distance = levenshtein_ratio_and_distance(contents,d1[val])\n",
    "#     print(Distance)\n",
    "    Ratio = levenshtein_ratio_and_distance(contents,d1[val],ratio_calc = True)\n",
    "    print(\"% match between resume and \"+val+\": \"+ Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_=[]\n",
    "for val in d1.keys():\n",
    "    list_.append(val+\" \"+d1[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=list_[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratios = process.extract(contents,list1)\n",
    "print(Ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest = process.extractOne(contents,list_)\n",
    "print(highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_dist(text1, text2, q=3, pad=True):\n",
    "    from scipy import spatial\n",
    "    text1, text2 = create_ngram(text1, text2, n=q, pad=pad)\n",
    "    \n",
    "    full_text = list(text1.union(text2))\n",
    "    v1 = [(lambda x: 1 if x in text1 else 0)(x) for x in full_text]\n",
    "    v2 = [(lambda x: 1 if x in text2 else 0)(x) for x in full_text]    \n",
    "    return spatial.distance.cosine(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(text, n=3, pad=True):\n",
    "    text = text.strip()\n",
    "    if pad:\n",
    "        text = \" %s \" % text\n",
    "    return set([text[i:i+n] for i in range(len(text)-n+1)])\n",
    "    \n",
    "def create_ngram(text1, text2, n=3, pad=True):\n",
    "    return ngram(text1, n=n, pad=pad), ngram(text2, n=n, pad=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qgrams(text1, text2, q=3, pad=True):\n",
    "    text1, text2 = create_ngram(text1, text2, n=q, pad=pad)\n",
    "    return len(text1.intersection(text2)),text1.intersection(text2)\n",
    "\n",
    "len,lis=qgrams(contents,d1['2173 Software engineers and designers'], q=10, pad=False) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_dist(text1, text2, q=3, pad=True):\n",
    "    text1, text2 = create_ngram(text1, text2, n=q, pad=pad)\n",
    "    \n",
    "    full_text = list(text1.union(text2))\n",
    "    agree_tot = len(text1.intersection(text2))\n",
    "    return 1 - agree_tot/float(len(full_text))\n",
    "\n",
    "jaccard_dist(contents,d1['2173 Software engineers and designers'], q=2, pad=False) #0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tversky_index(text1, text2, a=None, b=None, q=3, pad=True):\n",
    "    text1, text2 = create_ngram(text1, text2, n=q, pad=pad)\n",
    "    agree_tot = len(text1.intersection(text2))\n",
    "    v1 = len(text1) - agree_tot\n",
    "    v2 = len(text2) - agree_tot\n",
    "    \n",
    "    if a != None and b != None:\n",
    "        a = a/float(a+b)\n",
    "        b = b/float(a+b)\n",
    "    elif a <= 1.0 and a >= 0.0:\n",
    "        b = 1-a\n",
    "    elif b <= 1.0 and b >= 0.0:\n",
    "        a = 1-b\n",
    "    else:\n",
    "        a = 0.5\n",
    "        b = 0.5        \n",
    "    return float(agree_tot)/(agree_tot+a*v1+b*v2)\n",
    "    \n",
    "tversky_index(contents,d1['2173 Software engineers and designers'], a=0.5, q=2, pad=False) # 0.6666666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_dist(contents,d1['2173 Software engineers and designers'] , q=2, pad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1['2173 Software engineers and designers']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
